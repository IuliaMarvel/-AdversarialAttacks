{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ImLgQNzxG3XK"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import json \n",
        "from pathlib import Path\n",
        "import pickle\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f68xHbSGIfaN"
      },
      "outputs": [],
      "source": [
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "adf04175853c43c185f06021e8fc922b",
            "677ad23d9e8d415f8b3513f1c378981a",
            "a1266db2476146d18121707fba985a12",
            "da1b424486bf46c6a3b63066f49c601b",
            "947f1b43b15647f29804affcdaa5372a",
            "9cae37019cb542949cd379bd26816af5",
            "4edfe4e6b8ec4d409f6ac05099b067ed",
            "6bac262f212f47edabeb987ceede90bb",
            "32c8d2e391fd4cba928feaca70968a31",
            "8e7810937cdc46da9575c35afb00779e",
            "ddb813bd31804d5685757954621c5321"
          ]
        },
        "id": "VXgOu0pMIhx7",
        "outputId": "8d90b8f5-34fd-46b0-e2b6-3b53cb78948b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from efficientnet_pytorch) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=5667b7d3b2e367914a7b8141e29167d46dd24ed306980fce4f96087fdc62205d\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/b9/90/25a0195cf95fb5533db96f1c77ea3f296b7cc86ae8ae48e3dc\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b3-5fb5a3c3.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b3-5fb5a3c3.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/47.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adf04175853c43c185f06021e8fc922b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b3\n"
          ]
        }
      ],
      "source": [
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "model = EfficientNet.from_pretrained('efficientnet-b3', num_classes=200)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# Move model to designated device (Use GPU when on Colab)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaFwptsiIlDh",
        "outputId": "13536ede-baff-4de4-b8aa-dcdf2eaca47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading tiny-imagenet.zip to /content\n",
            "100% 473M/474M [00:22<00:00, 24.8MB/s]\n",
            "100% 474M/474M [00:22<00:00, 22.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "# your api key\n",
        "api_key = {\"username\":\"spacehitchhiker\",\"key\":\"c698b877d42f3f853d0a599e6263d8a8\"}\n",
        "\n",
        "# uses pathlib Path\n",
        "kaggle_path = Path('/root/.kaggle')\n",
        "os.makedirs(kaggle_path, exist_ok=True)\n",
        "\n",
        "# opens file and dumps python dict to json object \n",
        "with open (kaggle_path/'kaggle.json', 'w') as handl:\n",
        "    json.dump(api_key,handl)\n",
        "\n",
        "os.chmod(kaggle_path/'kaggle.json', 600)  \n",
        "\n",
        "!kaggle datasets download -d akash2sharma/tiny-imagenet\n",
        "\n",
        "!unzip -qq tiny-imagenet.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "fSx8xjoDIotG"
      },
      "outputs": [],
      "source": [
        "# Load all the images\n",
        "data_mean = (0.5071, 0.4865, 0.4409)\n",
        "data_std = (0.2673, 0.2564, 0.2762)\n",
        "\n",
        "data_path = '/content/tiny-imagenet-200/train'\n",
        "\n",
        "full_dataset = datasets.ImageFolder(\n",
        "    root=data_path\n",
        ")\n",
        "train_size = int(0.75 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "# use torch.utils.data.random_split for training/test split\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aGiiA1Nghl0",
        "outputId": "a162b8aa-d14d-4836-a6fb-548d95aec7a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'PIL.Image.Image'>\n"
          ]
        }
      ],
      "source": [
        "for x,y in train_dataset:\n",
        "  print(type(x)) \n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "j8Uo0gMGRzO1"
      },
      "outputs": [],
      "source": [
        "hard_classes = [24,42,49,65,94,99,131,159,172, 175, 197]\n",
        "easy_classes = [0,1,14,44,45,78,103,115,143,145, 165, 166,176, 183, 191]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUyzGwkdKFUv",
        "outputId": "e2df2ed1-fd8c-4757-a30c-6a4ffc934718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-0dcffe3143c0>:6: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  data = np.array(data)\n",
            "<ipython-input-11-0dcffe3143c0>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  data = np.array(data)\n"
          ]
        }
      ],
      "source": [
        "targets = [item[1] for item in train_dataset]\n",
        "data = [item[0] for item in train_dataset]\n",
        "X_all_sampled, y_all_sampled = [], []\n",
        "\n",
        "targets = np.array(targets)\n",
        "data = np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_targets = [item[1] for item in test_dataset]\n",
        "test_data = [item[0] for item in test_dataset]\n",
        "test_targets = np.array(test_targets)\n",
        "test_data = np.array(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYofr1_KKz_L",
        "outputId": "8a139597-9766-44c3-faa9-119ba35eea08"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-20fba35620ab>:4: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  test_data = np.array(test_data)\n",
            "<ipython-input-52-20fba35620ab>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  test_data = np.array(test_data)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kr3EGZUhKKhr"
      },
      "outputs": [],
      "source": [
        "data1,data2 = [],[]\n",
        "targets1,targets2 = [],[]\n",
        "for c in range(200):\n",
        "    X_all_c, y_all_c = data[targets==c],targets[targets==c]\n",
        "    if c in easy_classes:\n",
        "        num_samples = len(X_all_c)\n",
        "        sampled_indices = torch.randperm(num_samples)[:(num_samples//3)]\n",
        "    elif c in hard_classes:\n",
        "        num_samples = len(X_all_c)\n",
        "        sampled_indices = torch.randperm(num_samples)\n",
        "        data2.append(X_all_c[sampled_indices])\n",
        "        targets2.append(y_all_c[sampled_indices])\n",
        "    else:\n",
        "        num_samples = len(X_all_c)\n",
        "        sampled_indices = torch.randperm(num_samples)\n",
        "    data1.append(X_all_c[sampled_indices])\n",
        "    targets1.append(y_all_c[sampled_indices]) \n",
        "    \n",
        "data1 = np.concatenate(data1, axis=0)\n",
        "targets1 = np.concatenate(targets1, axis=0)\n",
        "data2 = np.concatenate(data2, axis=0)\n",
        "targets2 = np.concatenate(targets2, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TemOExHoK2Rt"
      },
      "outputs": [],
      "source": [
        "class ModifDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self,X,y,transform):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = (self.transform((self.X)[idx]),(self.y)[idx])\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm6urlBfu1-R",
        "outputId": "14dafc51-63c7-445a-ee46-31ae52e5d4d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "tr = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, .25, 0.25])])\n",
        "\n",
        "test_dataset = ModifDataset(test_data,test_targets,tr)\n",
        "\n",
        "for x,y in test_dataset:\n",
        "  print(type(x))\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "LwmG86J0PGOU"
      },
      "outputs": [],
      "source": [
        "tr1 = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, .25, 0.25])])\n",
        "\n",
        "tr2 = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(64),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.GaussianBlur(3,0.6),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "train_data1 = ModifDataset(data1,targets1,tr1)\n",
        "train_data2 = ModifDataset(data2,targets2,tr2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "B-_nVRiFRFX3"
      },
      "outputs": [],
      "source": [
        "train_dataset = torch.utils.data.ConcatDataset([train_data1,train_data2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5roORKaUgui",
        "outputId": "1824fdd7-e12c-4bf9-d8de-4059478f709e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75431 25000\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    num_workers=0,\n",
        "    shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    num_workers=0,\n",
        "    shuffle=False\n",
        ")\n",
        "print(len(train_dataset),len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_loader)*32,len(train_loader)*32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg4nGmLyHEbD",
        "outputId": "19a40379-d896-4e46-d9c2-e0e316481caf"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25024 75456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yeuDyKOdvtqK"
      },
      "outputs": [],
      "source": [
        "def clamp(X, lower_limit, upper_limit):\n",
        "    return torch.max(torch.min(X, upper_limit), lower_limit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "y5wakhKAsHnq"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 200\n",
        "\n",
        "def attack_pgd(model, X, y, epsilon, alpha, attack_iters, restarts, lower_limit, upper_limit, args=None):\n",
        "\n",
        "    max_loss = torch.zeros(y.shape[0]).to(device)\n",
        "    max_delta = torch.zeros_like(X).to(device)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for _ in range(restarts):\n",
        "        delta = torch.zeros_like(X).to(device)\n",
        "        for i in range(len(epsilon)):\n",
        "            delta[:, i, :, :].uniform_(-epsilon[i][0][0].item(), epsilon[i][0][0].item())\n",
        "        delta.data = clamp(delta, lower_limit - X, upper_limit - X)\n",
        "        delta.requires_grad = True\n",
        "\n",
        "        for _ in range(attack_iters):\n",
        "            with torch.cuda.amp.autocast():\n",
        "                output = model(X + delta)\n",
        "                index = torch.where(output.max(1)[1] == y)[0]\n",
        "                if len(index) == 0:\n",
        "                    break\n",
        "                loss = F.cross_entropy(output, y)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            grad = delta.grad.detach()\n",
        "\n",
        "            d = delta[index, :, :, :]\n",
        "            g = grad[index, :, :, :]\n",
        "            d = clamp(d + alpha * torch.sign(g), -epsilon, epsilon)\n",
        "            d = clamp(d, lower_limit - X[index, :, :, :], upper_limit - X[index, :, :, :])\n",
        "\n",
        "            delta.data[index, :, :, :] = d\n",
        "            delta.grad.zero_()\n",
        "\n",
        "        all_loss = F.cross_entropy(model(X + delta), y, reduction='none').detach()\n",
        "        max_delta[all_loss >= max_loss] = delta.detach()[all_loss >= max_loss]\n",
        "        max_loss = torch.max(max_loss, all_loss)\n",
        "\n",
        "    return max_delta\n",
        "\n",
        "\n",
        "def evaluate_pgd(test_loader, model, attack_iters, restarts, epsilon, alpha, lower_limit, upper_limit, args=None):\n",
        "\n",
        "    examples_per_class = {i : 0 for i in range(NUM_CLASSES)}\n",
        "    correct_per_class = {i : 0 for i in range(NUM_CLASSES)}\n",
        "\n",
        "    pgd_loss, pgd_acc = 0, 0\n",
        "    n = 0\n",
        "    model.eval()\n",
        "    for i, (X, y) in enumerate(test_loader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pgd_delta = attack_pgd(model, X, y, epsilon, alpha, attack_iters, restarts, lower_limit, upper_limit, args=args)\n",
        "        with torch.no_grad():\n",
        "            output = model(X + pgd_delta)\n",
        "            preds = output.max(1)[1]\n",
        "            for i in range(NUM_CLASSES):\n",
        "                examples_per_class[i] += len(y[y==i])\n",
        "                correct_per_class[i] += (preds[y==i] == i).sum().item()\n",
        "            loss = F.cross_entropy(output, y)\n",
        "            pgd_loss += loss.item() * y.size(0)\n",
        "            pgd_acc += (output.max(1)[1] == y).sum().item()\n",
        "            n += y.size(0)\n",
        "        acc_per_class = {}\n",
        "    for i in range(NUM_CLASSES):\n",
        "        acc_per_class[i] = correct_per_class[i] / examples_per_class[i]\n",
        "    return pgd_loss/n, pgd_acc/n,acc_per_class\n",
        "\n",
        "\n",
        "def evaluate_standard(test_loader, model, args=None):\n",
        "    \n",
        "    examples_per_class = {i : 0 for i in range(NUM_CLASSES)}\n",
        "    correct_per_class = {i : 0 for i in range(NUM_CLASSES)}\n",
        "    \n",
        "    test_loss, test_acc = 0, 0\n",
        "    n = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (X, y) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            output = model(X)\n",
        "            preds = output.max(1)[1]\n",
        "            for i in range(NUM_CLASSES):\n",
        "                examples_per_class[i] += len(y[y==i])\n",
        "                correct_per_class[i] += (preds[y==i] == i).sum().item()\n",
        "            loss = F.cross_entropy(output, y)\n",
        "            test_loss += loss.item() * y.size(0)\n",
        "            test_acc += (output.max(1)[1] == y).sum().item()\n",
        "            n += y.size(0)\n",
        "    acc_per_class = {}\n",
        "    for i in range(NUM_CLASSES):\n",
        "        acc_per_class[i] = correct_per_class[i] / examples_per_class[i]\n",
        "    return test_loss/n, test_acc/n,acc_per_class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "VXw5ckTWWK21"
      },
      "outputs": [],
      "source": [
        "weight_decay = 5e-4\n",
        "epsilon = 8\n",
        "batch_size = 32\n",
        "alpha = 2\n",
        "loss_weight = 0.3\n",
        "fgsm_step = 1\n",
        "delta_init = 'random'\n",
        "model.train()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=3e-4,weight_decay=weight_decay)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "data_mean = (0.5071, 0.4865, 0.4409)\n",
        "data_std = (0.2673, 0.2564, 0.2762)\n",
        "\n",
        "mu = torch.tensor(data_mean).view(3, 1, 1).to(device)\n",
        "std = torch.tensor(data_std).view(3, 1, 1).to(device)\n",
        "upper_limit = ((1 - mu) / std)\n",
        "lower_limit = ((0 - mu) / std)\n",
        "epsilon = (epsilon / 255.) / std\n",
        "alpha = (alpha / 255.) / std\n",
        "\n",
        "if delta_init == 'previous':\n",
        "    delta = torch.zeros(batch_size, 3, 32, 32).to(device)\n",
        "\n",
        "prev_robust_acc = 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAO5xFY4QlL2",
        "outputId": "18e83acf-2e37-4e01-9ef8-f7fcffde6f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train acc: 0.289 test acc: 0.30884:  40%|████      | 4/10 [1:21:53<2:02:45, 1227.64s/it]"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr=3e-4,weight_decay=weight_decay)\n",
        "\n",
        "epochs = 10\n",
        "loop = tqdm(range(epochs))\n",
        "for epoch in loop:\n",
        "    train_loss,train_acc,train_n = 0,0,0\n",
        "    # if epoch > 12:\n",
        "    #   optimizer.param_groups[0]['lr'] = 1e-4\n",
        "    model.train()\n",
        "    for i, (X, y) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        if delta_init != 'previous':\n",
        "            delta = torch.zeros_like(X).to(device)\n",
        "        if delta_init == 'random':\n",
        "            for j in range(len(epsilon)):\n",
        "                delta[:, j, :, :].uniform_(-epsilon[j][0][0].item(), epsilon[j][0][0].item())\n",
        "            delta.data = clamp(delta, lower_limit - X, upper_limit - X)\n",
        "        if fgsm_step == 1:\n",
        "            delta.requires_grad = True\n",
        "            for _ in range(1):\n",
        "                output = model(X + delta[:X.size(0)])\n",
        "                loss = F.cross_entropy(output, y)\n",
        "                scaler.scale(loss).backward()\n",
        "                grad = delta.grad.detach()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                delta.data = clamp(delta + alpha * torch.sign(grad), -epsilon, epsilon)\n",
        "                delta.data[:X.size(0)] = clamp(delta[:X.size(0)], lower_limit - X, upper_limit - X)\n",
        "            delta = delta.detach()\n",
        "            output = model(X + delta[:X.size(0)])\n",
        "            loss = (1 - loss_weight) * criterion(output, y) + loss_weight * criterion(model(X), y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            \n",
        "        train_loss += loss.item() * y.size(0)\n",
        "        train_acc += (output.max(1)[1] == y).sum().item()\n",
        "        train_n += y.size(0)\n",
        "      \n",
        "    model.eval()\n",
        "    pgd_loss, pgd_acc, acc_cl_pgd_at = evaluate_pgd(test_loader, model, 1, 5, epsilon, alpha, \n",
        "                                  lower_limit, upper_limit)\n",
        "    \n",
        "    if pgd_acc >= 0.4:\n",
        "      best_state_dict = model.state_dict()\n",
        "      torch.save(best_state_dict,'model_default_good.pth')\n",
        "      \n",
        "    loop.set_description(f'train acc: {round(train_acc / train_n,3)} test acc: {pgd_acc}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "adf04175853c43c185f06021e8fc922b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_677ad23d9e8d415f8b3513f1c378981a",
              "IPY_MODEL_a1266db2476146d18121707fba985a12",
              "IPY_MODEL_da1b424486bf46c6a3b63066f49c601b"
            ],
            "layout": "IPY_MODEL_947f1b43b15647f29804affcdaa5372a"
          }
        },
        "677ad23d9e8d415f8b3513f1c378981a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cae37019cb542949cd379bd26816af5",
            "placeholder": "​",
            "style": "IPY_MODEL_4edfe4e6b8ec4d409f6ac05099b067ed",
            "value": "100%"
          }
        },
        "a1266db2476146d18121707fba985a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bac262f212f47edabeb987ceede90bb",
            "max": 49388949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32c8d2e391fd4cba928feaca70968a31",
            "value": 49388949
          }
        },
        "da1b424486bf46c6a3b63066f49c601b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e7810937cdc46da9575c35afb00779e",
            "placeholder": "​",
            "style": "IPY_MODEL_ddb813bd31804d5685757954621c5321",
            "value": " 47.1M/47.1M [00:07&lt;00:00, 7.80MB/s]"
          }
        },
        "947f1b43b15647f29804affcdaa5372a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cae37019cb542949cd379bd26816af5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4edfe4e6b8ec4d409f6ac05099b067ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bac262f212f47edabeb987ceede90bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32c8d2e391fd4cba928feaca70968a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e7810937cdc46da9575c35afb00779e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb813bd31804d5685757954621c5321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}